# pr_pilot/analysis/deepseek.py
import openai
from .base import AIAnalyzer, AnalysisInput, PRContext # <-- ã€ä¿®æ­£ã€‘å¯¼å…¥ PRContext
import prompts
import config
import json
import os # <-- å¼•å…¥ os æ¨¡å—
import datetime 
# --- ã€æ–°å¢ã€‘ä¸ºç¬¬ä¸€é˜¶æ®µçš„â€œåˆ†æå‘˜â€è®¾è®¡ä¸“é—¨çš„ç³»ç»ŸæŒ‡ä»¤ ---
# è¿™ä¸ªæŒ‡ä»¤éå¸¸å…³é”®ï¼Œå®ƒå‘Šè¯‰ AI ä¸è¦å†™å®Œæ•´çš„æŠ¥å‘Šï¼Œè€Œæ˜¯è¿”å›ä¸€ä¸ªç»“æ„åŒ–çš„ JSONã€‚
ANALYST_SYSTEM_PROMPT = """
You are a junior AI code analyst. Your task is to analyze a potential relationship between a main code change and a single related code snippet from the repository.
Your analysis must be concise and focused.
You MUST respond ONLY with a single JSON object, with no other text before or after it.

The JSON object must have the following structure:
{
  "impact_summary": "A brief, one-sentence summary of the potential impact the main change could have on the related snippet.",
  "risk_score": An integer from 1 (no risk) to 10 (critical risk of breaking changes or severe side-effects).,
  "impact_type": "Categorize the impact type. Examples: 'Logic Error', 'Data Flow Inconsistency', 'Redundant Code', 'Architectural Mismatch', 'No Significant Impact'.",
  "critical_code_block": "Extract a self-contained block of code from the 'Related Code Snippet' that is MOST RELEVANT to your analysis. Aim for a concise block, IDEALLY AROUND 5-15 LINES, that provides enough context to understand the risk. You have the flexibility to go slightly shorter or longer if it is critical for preserving the logical integrity of the code. The goal is clarity and relevance, not strict line counting."
}
"""

class DeepSeekAnalyzer(AIAnalyzer):
    def __init__(self, api_key: str = config.DEEPSEEK_API_KEY):
        if not api_key:
            raise ValueError("DeepSeek API key is not configured.")
        self.client = openai.OpenAI(
            api_key=api_key,
            base_url=config.DEEPSEEK_BASE_URL,
            timeout=120.0,
            max_retries=3
        )
        print("DeepSeek Analyzer initialized.")

    # --- ã€æ–°å¢ã€‘å®ç°ç¼ºå¤±çš„â€œåˆ†æå‘˜â€å‡½æ•° ---
    def _get_preliminary_analysis(self, main_change_context: str, related_snippet: str) -> dict:
        """
        [ç¬¬ä¸€é˜¶æ®µ - åˆ†æå‘˜]
        å¯¹å•ä¸ªä»£ç ç‰‡æ®µè¿›è¡Œåˆæ­¥åˆ†æï¼Œå¹¶è¿”å›åŒ…å« critical_quote çš„ç»“æ„åŒ– JSON æŠ¥å‘Šã€‚
        """
        # ä¸ºåˆ†æå‘˜æ„å»ºä¸“ç”¨çš„ User Prompt
        user_prompt = f"""
        ### Main Change Context
        This section contains the full context of the pull request, including file contents and diffs.
        {main_change_context}

        ---

        ### Related Code Snippet from Repository
        This is the specific code snippet you need to analyze in relation to the main change.
        ```
        {related_snippet}
        ```

        ---

        Based on the full context above, provide your analysis for the 'Related Code Snippet' in the required JSON format.
        """
        try:
            response = self.client.chat.completions.create(
                model=config.DEEPSEEK_MODEL,
                messages=[
                    # ä½¿ç”¨æˆ‘ä»¬æ–°çš„ã€å‡çº§ç‰ˆçš„ç³»ç»ŸæŒ‡ä»¤
                    {"role": "system", "content": ANALYST_SYSTEM_PROMPT}, 
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.1,
                # å¼ºåˆ¶è¦æ±‚è¿”å› JSONï¼Œè¿™èƒ½æå¤§æå‡ç¨³å®šæ€§å’ŒæˆåŠŸç‡
                response_format={"type": "json_object"} 
            )
            report_str = response.choices[0].message.content

            if not report_str:
                raise json.JSONDecodeError("Empty content from API", "", 0)

            # è§£æè¿”å›çš„ JSON å­—ç¬¦ä¸²
            return json.loads(report_str)
            
        except Exception as e:
            print(f"  - âŒ Analyst failed for a snippet: {e}")
            # å¦‚æœå¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªç¬¦åˆæ–°æ ¼å¼çš„é”™è¯¯å­—å…¸
            return {
                "impact_summary": "Failed to analyze this snippet due to an error.",
                "risk_score": 0,
                "impact_type": "Analysis Error",
                "critical_quote": ""
            }


    # --- ã€ä¿®æ­£ã€‘ä¿®å¤å•é˜¶æ®µåˆ†æçš„å…¨éƒ¨ Bug ---
    def _analyze_single_stage(self, analysis_input: AnalysisInput) -> str:
        """
        [å•é˜¶æ®µ V2.0]
        å°†ç»“æ„åŒ–çš„æ•°æ®â€œæ ¼å¼åŒ–â€æˆæœ€ç»ˆå‘é€ç»™LLMçš„å·¨å¤§å­—ç¬¦ä¸²ã€‚
        """
        print("Running single-stage analysis...")
        pr_context_structured: PRContext = analysis_input["pr_context"]
        repo_config = pr_context_structured["repo_config"] # <-- ã€ä¿®æ­£ã€‘ä»æ­£ç¡®çš„ä½ç½®è·å– repo_config

        # --- ã€ä¿®æ­£ã€‘å°†æ‰€æœ‰ç»“æ„åŒ–æ•°æ®é‡æ–°ç»„åˆæˆä¸€ä¸ªå®Œæ•´çš„ Prompt å­—ç¬¦ä¸² ---
        context_list = [pr_context_structured["main_context"]]

        # æ ¼å¼åŒ–ä¾èµ–é“¾
        if pr_context_structured["dependency_chains"]:
            chains = pr_context_structured["dependency_chains"]
            context_list.append("\n---\n")
            context_list.append("### â›“ï¸ CRITICAL: Dependency Chains Detected!\n")
            context_list.append("These functions are connected to your changes through direct or indirect calls. Changes in one might unexpectedly affect the other.\n")
            for chain in sorted(list(set(chains))):
                context_list.append(f"- `{chain}`\n")

        # æ ¼å¼åŒ–RAGç»“æœ
        if pr_context_structured["related_snippets"]:
            snippets = pr_context_structured["related_snippets"]
            context_list.append("\n---\n")
            context_list.append("### ğŸ“š Potentially Related Code from the Repository\n")
            context_list.append("Below are the most semantically related code snippets based on content similarity:\n\n")
            for snippet in snippets:
                context_list.append("```\n")
                context_list.append(snippet)
                context_list.append("\n```\n\n")

        final_context_string = "\n".join(context_list) # <-- ã€ä¿®æ­£ã€‘åˆ›å»ºæœ€ç»ˆçš„å­—ç¬¦ä¸²å˜é‡

        # --- æ„å»º System Prompt (å’ŒåŸæ¥ä¸€æ ·) ---
        system_prompt = prompts.DEFAULT_SYSTEM_PROMPT
        if repo_config and 'rules' in repo_config:
            print("å‘ç°è‡ªå®šä¹‰è§„åˆ™ï¼Œæ­£åœ¨æ³¨å…¥Prompt...")
            custom_rules = "\n".join([f"- {rule}" for rule in repo_config['rules']])
            rules_section = (
                "\n\n### ğŸ“ é¡¹ç›®ç‰¹å®šå®¡æŸ¥è§„åˆ™\n"
                "é™¤äº†é€šç”¨ä»£ç å®¡æŸ¥å¤–ï¼Œè¯·åŠ¡å¿…ä¸¥æ ¼æ£€æŸ¥å¹¶æŠ¥å‘Šä»¥ä¸‹é¡¹ç›®ç‰¹å®šè§„åˆ™æ˜¯å¦è¢«éµå®ˆï¼š\n"
                f"{custom_rules}"
            )
            system_prompt += rules_section

        # --- è°ƒè¯•ä¸ API è°ƒç”¨ ---
        try:
            print("Sending request to DeepSeek API...")
            response = self.client.chat.completions.create(
                model=config.DEEPSEEK_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": final_context_string} # <-- ã€ä¿®æ­£ã€‘ä½¿ç”¨æ­£ç¡®çš„å˜é‡
                ],
                temperature=config.TEMPERATURE,
            )
            analysis = response.choices[0].message.content
            print("Successfully received analysis from DeepSeek.")
            return analysis
        except openai.APIError as e:
            print(f"Error from DeepSeek API: {e}")
            raise
        except Exception as e:
            print(f"An unexpected error occurred during single-stage analysis: {e}")
            raise

    # --- ã€ä¿®æ­£ã€‘å®Œå–„ä¸¤é˜¶æ®µåˆ†æçš„ Prompt æ„å»º ---
    def _analyze_two_stage(self, analysis_input: AnalysisInput) -> str:
        """
        [æ–°æ¶æ„ - ä¸¤é˜¶æ®µ V2.0]
        ç¼–æ’â€œåˆ†æå‘˜-æ€»æŒ‡æŒ¥â€æµç¨‹ï¼Œå…ˆå¹¶è¡Œæ”¶é›†æƒ…æŠ¥ï¼Œå†è¿›è¡Œç»¼åˆç ”åˆ¤ã€‚
        """
        print("Starting two-stage analysis with structured data...")
        pr_context_structured: PRContext = analysis_input["pr_context"]
        full_main_context = pr_context_structured["main_context"]         # <-- å®Œæ•´ç‰ˆï¼Œåªç»™åˆ†æå‘˜
        lean_main_context = pr_context_structured["lean_main_context"] 
        
        related_code_snippets = pr_context_structured["related_snippets"]
        dependency_chains = pr_context_structured["dependency_chains"]
        historical_warnings = pr_context_structured.get("historical_warnings", [])
        clone_warnings = pr_context_structured.get("clone_warnings", [])

        if not related_code_snippets:
            print("No related snippets found. Falling back to single-stage analysis.")
            return self._analyze_single_stage(analysis_input)

        # --- [ç¬¬ä¸€é˜¶æ®µ] å¹¶è¡Œè°ƒç”¨â€œåˆ†æå‘˜â€ (ç°åœ¨å¯ä»¥å·¥ä½œäº†) ---
        print(f"Found {len(related_code_snippets)} related snippets. Dispatching analysts...")
        preliminary_reports = []
        for i, snippet in enumerate(related_code_snippets):
            print(f"  - Analyzing snippet {i+1}/{len(related_code_snippets)}...")
            report = self._get_preliminary_analysis(full_main_context, snippet)
            report['original_snippet'] = snippet
            preliminary_reports.append(report)

        # --- [ç¬¬äºŒé˜¶æ®µ] æ„å»ºâ€œæ€»æŒ‡æŒ¥â€çš„æœ€ç»ˆ Prompt ---
        preliminary_reports.sort(key=lambda r: r.get('risk_score', 0), reverse=True)
        TOP_N_EVIDENCE = 3
        
        critical_evidence_text = "\n\n---\n\n".join([
            f"--- Critical Evidence #{i+1} (Risk: {report.get('risk_score')}/10) ---\n"
            "```\n"
            f"{report.get('original_snippet', 'N/A')}\n"
            "```"
            for i, report in enumerate(preliminary_reports[:TOP_N_EVIDENCE])
            if report.get('risk_score', 0) > 3
        ])

        briefing_text = "\n\n".join([
            f"Analyst Report #{i+1}:\n" +
            f"- Impact Summary: {report.get('impact_summary', 'N/A')}\n" +
            f"- Risk Score: {report.get('risk_score', 'N/A')}/10\n" +
            f"- Impact Type: {report.get('impact_type', 'N/A')}"
            for i, report in enumerate(preliminary_reports)
        ])
        
        # ã€æ–°å¢ã€‘å°†ä¾èµ–é“¾ä¿¡æ¯ä¹ŸåŠ å…¥åˆ°æœ€ç»ˆæƒ…æŠ¥ä¸­
        dependency_chains_text = ""
        if dependency_chains:
            chains_str_list = []
            for chain in sorted(list(set(dependency_chains))):
                chains_str_list.append(f"- **Chain**: `{chain}`\n  - **Potential Risk**: [AI to fill this in]")
            
            chains_str = "\n".join(chains_str_list)
            
            dependency_chains_text = f"""
            ### â›“ï¸ CRITICAL: Dependency Chains Detected!
            Here are the critical dependency chains related to your changes. You MUST analyze the potential risk for EACH chain in your final report.
            {chains_str}
            """

        final_system_prompt = prompts.DEFAULT_SYSTEM_PROMPT
        final_user_prompt = f"""
        {lean_main_context}
        {historical_warnings if historical_warnings else "" }
        {dependency_chains_text}

        ### Intelligence Briefing from Analyst Team
        {briefing_text}

        ### Appendix: High-Risk Code Snippets
        {critical_evidence_text if critical_evidence_text else "No high-risk snippets were identified by the analyst team."}
        
        ### Your Task as Chief Architect
        Based on all the information above (main context, dependency map, intelligence briefing, and high-risk snippets), synthesize the findings and write the final, comprehensive code review report.
        """
        
        # --- è°ƒç”¨ LLM è¿›è¡Œæœ€ç»ˆç ”åˆ¤ ---
        try:
            try:
                debug_info = analysis_input.get("debug_info")
                if debug_info:
                    # 1. æ ¹æ® debug_info æ„å»ºä¸€ä¸ªä¸ .md æ–‡ä»¶æ ¼å¼ä¸€è‡´çš„æ–‡ä»¶å
                    repo = debug_info['repo_name'].replace('/', '_')
                    pr_num = debug_info['pr_number']
                    retrieval = debug_info['retrieval_mode']
                    analysis = debug_info['analysis_mode']
                    k = debug_info['top_k']
                    
                    debug_filename = f"{repo}_pr_{pr_num}_retrieval-{retrieval}_analysis-{analysis}_k{k}_prompt.txt"
                else:
                    # 2. å¦‚æœæ²¡æœ‰ debug_infoï¼Œæä¾›ä¸€ä¸ªå¸¦æ—¶é—´æˆ³çš„å¤‡ç”¨æ–¹æ¡ˆ
                    now = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                    debug_filename = f"stage_two_prompt_{now}.txt"

                # 3. åˆ›å»ºæ–‡ä»¶å¤¹å¹¶å†™å…¥æ–‡ä»¶
                output_dir = "debug_prompts"
                os.makedirs(output_dir, exist_ok=True)
                full_path = os.path.join(output_dir, debug_filename)

                with open(full_path, "w", encoding="utf-8") as f:
                    f.write("========== SYSTEM PROMPT (CHIEF ARCHITECT) ==========\n")
                    f.write(final_system_prompt)
                    f.write("\n\n" + "="*80 + "\n\n")
                    f.write("========== USER PROMPT (CHIEF ARCHITECT) ==========\n")
                    f.write(final_user_prompt)
                print(f"âœ… [è°ƒè¯•] ç¬¬äºŒé˜¶æ®µ Prompt å·²ä¿å­˜åˆ°: {full_path}")

            except Exception as e:
                # ç¡®ä¿æ—¥å¿—è®°å½•å¤±è´¥ä¸ä¼šä¸­æ–­ä¸»æµç¨‹
                print(f"âŒ [è°ƒè¯•] ä¿å­˜ç¬¬äºŒé˜¶æ®µ Prompt æ–‡ä»¶å¤±è´¥: {e}")
            print("Briefing complete. Requesting final synthesis from the Chief Architect...")
            response = self.client.chat.completions.create(
                model=config.DEEPSEEK_MODEL,
                messages=[
                    {"role": "system", "content": final_system_prompt},
                    {"role": "user", "content": final_user_prompt}
                ],
                temperature=config.TEMPERATURE,
            )
            final_review = response.choices[0].message.content
            print("Successfully received final analysis from Chief Architect.")
            return final_review
        except Exception as e:
            print(f"An unexpected error occurred during two-stage analysis: {e}")
            raise
    # def _analyze_two_stage(self, analysis_input: AnalysisInput) -> str:
    #     """
    #     [ä¸´æ—¶æµ‹è¯•ç‰ˆæœ¬] - ä»…ç”¨äºæµ‹è¯•é˜¶æ®µä¸€ (åˆ†æå‘˜) çš„è¾“å…¥å’Œè¾“å‡ºã€‚
    #     """
    #     print("--- [å¯åŠ¨é˜¶æ®µä¸€æµ‹è¯•æ¨¡å¼] ---")
    #     pr_context_structured: PRContext = analysis_input["pr_context"]

    #     # --- 1. å‡†å¤‡è¾“å…¥æ•°æ® ---
    #     full_main_context = pr_context_structured["main_context"]
    #     related_code_snippets = pr_context_structured["related_snippets"]

    #     if not related_code_snippets:
    #         print("é”™è¯¯: RAG æœªæ£€ç´¢åˆ°ä»»ä½•ç›¸å…³ä»£ç ç‰‡æ®µï¼Œæ— æ³•è¿›è¡Œæµ‹è¯•ã€‚")
    #         return "Test Failed: No snippets found."

    #     # æˆ‘ä»¬åªæµ‹è¯•ç¬¬ä¸€ä¸ªæ£€ç´¢åˆ°çš„ä»£ç ç‰‡æ®µ
    #     test_snippet = related_code_snippets[0]

    #     # ã€ã€ã€ã€ã€ æ ¸å¿ƒæµ‹è¯•åŒºåŸŸ START ã€‘ã€‘ã€‘ã€‘ã€‘
    #     print("\n--- [é˜¶æ®µä¸€è¾“å…¥ Input] ---")
    #     print("1. å‘é€ç»™åˆ†æå‘˜çš„ main_change_context (å‰500ä¸ªå­—ç¬¦):")
    #     print(full_main_context[:500] + "...")
    #     print("\n" + "="*50 + "\n")
    #     print("2. å‘é€ç»™åˆ†æå‘˜çš„ related_snippet (å®Œæ•´å†…å®¹):")
    #     print("```python")
    #     print(test_snippet)
    #     print("```")

    #     print("\n--- [æ­£åœ¨è°ƒç”¨åˆ†æå‘˜API...] ---")
        
    #     # è°ƒç”¨æˆ‘ä»¬æƒ³è¦æµ‹è¯•çš„æ ¸å¿ƒå‡½æ•°
    #     report = self._get_preliminary_analysis(full_main_context, test_snippet)

    #     print("\n--- [é˜¶æ®µä¸€è¾“å‡º Output] ---")
    #     print("åˆ†æå‘˜è¿”å›çš„ JSON å¯¹è±¡:")
    #     # ä½¿ç”¨ json.dumps ç¾åŒ–æ‰“å°è¾“å‡º
    #     print(json.dumps(report, indent=2, ensure_ascii=False))
    #     # ã€ã€ã€ã€ã€ æ ¸å¿ƒæµ‹è¯•åŒºåŸŸ END ã€‘ã€‘ã€‘ã€‘ã€‘

    #     print("\n--- [æµ‹è¯•å®Œæˆï¼Œç¨‹åºå°†é€€å‡º] ---")
    #     exit() # ç«‹å³é€€å‡ºï¼Œä¸æ‰§è¡Œåç»­ä»»ä½•æ“ä½œ

    #     # åç»­çš„æ€»æŒ‡æŒ¥é€»è¾‘æš‚æ—¶ä¸ä¼šè¢«æ‰§è¡Œ
    #     return "This part will not be reached."

    def analyze(self, analysis_input: AnalysisInput) -> str:
        """
        [è°ƒåº¦ä¸­å¿ƒ]
        æ ¹æ®ä¼ å…¥çš„ analysis_modeï¼Œå†³å®šä½¿ç”¨å•é˜¶æ®µè¿˜æ˜¯ä¸¤é˜¶æ®µæ¶æ„ã€‚
        """
        mode = analysis_input.get("analysis_mode", "single")

        if mode == "two-stage":
            return self._analyze_two_stage(analysis_input)
        else:
            return self._analyze_single_stage(analysis_input)